import { getAIRequestConfig, createAIRequestBody, isAIConfigValid, getAIConfig } from './aiConfig'

/**
 * å›¾åƒåˆ†æè¯·æ±‚å‚æ•°
 */
export interface ImageAnalysisRequest {
  image: string // base64 ç¼–ç çš„å›¾åƒæ•°æ®
  targetWord: string // ç›®æ ‡è¯æ±‡
  prompt?: string // è‡ªå®šä¹‰æç¤ºè¯
}

/**
 * AI åˆ†æç»“æœ
 */
export interface AIAnalysisResult {
  success: boolean
  confidence: number // ç½®ä¿¡åº¦ 0-1
  analysis: string // åˆ†ææè¿°
  suggestion?: string // æ”¹è¿›å»ºè®®
  error?: string // é”™è¯¯ä¿¡æ¯
}

/**
 * è°ƒç”¨ AI æœåŠ¡åˆ†æç»˜ç”»å›¾åƒ
 */
export const analyzeDrawing = async (request: ImageAnalysisRequest): Promise<AIAnalysisResult> => {
  try {
    // æ£€æŸ¥é…ç½®æ˜¯å¦æœ‰æ•ˆ
    if (!isAIConfigValid(undefined, 'vision')) {
      return {
        success: false,
        confidence: 0,
        analysis: 'é…ç½®é”™è¯¯',
        error: 'è§†è§‰æ¨¡å‹é…ç½®ä¸å®Œæ•´ï¼Œè¯·å…ˆåœ¨è®¾ç½®é¡µé¢é…ç½®è§†è§‰æ¨¡å‹æœåŠ¡å‚æ•°'
      }
    }

    // è·å–é…ç½®ä¿¡æ¯
    const { url, headers } = getAIRequestConfig('vision')

    // æ„å»ºæç¤ºè¯
    const defaultPrompt = `è¯·åˆ†æè¿™å¹…ç»˜ç”»æ˜¯å¦è¡¨ç°äº†"${request.targetWord}"ã€‚

åˆ†æè¦æ±‚ï¼š
1. ä»”ç»†è§‚å¯Ÿå›¾åƒä¸­çš„çº¿æ¡ã€å½¢çŠ¶ã€ç»“æ„
2. åˆ¤æ–­æ˜¯å¦èƒ½è¯†åˆ«å‡ºç›®æ ‡è¯æ±‡çš„ç‰¹å¾
3. ç»™å‡º0-1ä¹‹é—´çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ1ä¸ºå®Œå…¨åŒ¹é…ï¼‰
4. æä¾›å…·ä½“çš„åˆ†æè¯´æ˜
5. å¦‚æœè¯†åˆ«åº¦ä¸é«˜ï¼Œè¯·ç»™å‡ºæ”¹è¿›å»ºè®®

è¯·ç”¨JSONæ ¼å¼è¿”å›ç»“æœï¼š
{
  "confidence": 0.8,
  "analysis": "è¯¦ç»†åˆ†ææè¿°",
  "suggestion": "æ”¹è¿›å»ºè®®ï¼ˆå¯é€‰ï¼‰"
}`

    const finalPrompt = request.prompt || defaultPrompt

    // æ„å»ºè¯·æ±‚æ¶ˆæ¯
    const messages = [
      {
        role: 'user',
        content: [
          {
            type: 'text',
            text: finalPrompt
          },
          {
            type: 'image',
            image: request.image
          }
        ]
      }
    ]

    // åˆ›å»ºè¯·æ±‚ä½“
    const requestBody = createAIRequestBody(messages, 'vision', {
      temperature: 0.3, // è¾ƒä½çš„æ¸©åº¦å€¼ï¼Œä¿è¯ç»“æœç¨³å®š
      max_tokens: 500,
      top_p: 0.8
    })

    // å‘é€è¯·æ±‚
    const response = await fetch(url, {
      method: 'POST',
      headers,
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
    }

    const data = await response.json()
    
    // è§£æå“åº”
    if (data.choices && data.choices.length > 0) {
      const content = data.choices[0].message?.content
      
      try {
        // å°è¯•è§£æ JSON å“åº”
        const parsed = JSON.parse(content)
        return {
          success: true,
          confidence: Math.max(0, Math.min(1, parsed.confidence || 0)),
          analysis: parsed.analysis || content,
          suggestion: parsed.suggestion
        }
      } catch {
        // å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥ä½¿ç”¨æ–‡æœ¬å†…å®¹
        return {
          success: true,
          confidence: 0.5, // é»˜è®¤ç½®ä¿¡åº¦
          analysis: content || 'åˆ†æå®Œæˆï¼Œä½†æ— æ³•è·å–è¯¦ç»†ç»“æœ'
        }
      }
    } else {
      throw new Error('API å“åº”æ ¼å¼å¼‚å¸¸')
    }

  } catch (error) {
    console.error('AI åˆ†æå¤±è´¥:', error)
    return {
      success: false,
      confidence: 0,
      analysis: 'åˆ†æå¤±è´¥',
      error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
    }
  }
}

/**
 * ç”Ÿæˆç»˜ç”»å»ºè®®
 */
export const generateDrawingSuggestion = async (targetWord: string): Promise<string> => {
  try {
    if (!isAIConfigValid(undefined, 'vision')) {
      return 'è¯·å…ˆé…ç½®è§†è§‰æ¨¡å‹æœåŠ¡ä»¥è·å–ç»˜ç”»å»ºè®®'
    }

    const { url, headers } = getAIRequestConfig('vision')

    const prompt = `è¯·ä¸ºç»˜ç”»ä¸»é¢˜"${targetWord}"æä¾›ç®€æ´çš„ç»˜ç”»å»ºè®®ï¼ŒåŒ…æ‹¬ï¼š
1. å…³é”®ç‰¹å¾å’Œå½¢çŠ¶
2. é‡è¦çš„ç»†èŠ‚éƒ¨åˆ†
3. ç®€å•æ˜“æ‡‚çš„ç»˜ç”»æŠ€å·§

è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€ï¼Œä¸è¶…è¿‡100å­—ã€‚`

    const messages = [
      {
        role: 'user',
        content: prompt
      }
    ]

    const requestBody = createAIRequestBody(messages, 'vision', {
      temperature: 0.7,
      max_tokens: 200
    })

    const response = await fetch(url, {
      method: 'POST',
      headers,
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      throw new Error(`è¯·æ±‚å¤±è´¥: ${response.status}`)
    }

    const data = await response.json()
    return data.choices?.[0]?.message?.content || 'æš‚æ—¶æ— æ³•è·å–ç»˜ç”»å»ºè®®'

  } catch (error) {
    console.error('è·å–ç»˜ç”»å»ºè®®å¤±è´¥:', error)
    return 'è·å–å»ºè®®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ AI é…ç½®'
  }
}

/**
 * æ£€æŸ¥ AI æœåŠ¡è¿æ¥çŠ¶æ€
 * å‚è€ƒæ ‡å‡† OpenAI API æ ¼å¼å‘é€æµ‹è¯•è¯·æ±‚
 * curl https://api.openai.com/v1/chat/completions \
 * -H "Content-Type: application/json" \
 * -H "Authorization: Bearer $OPENAI_API_KEY" \
 * -d '{"model": "gpt-3.5-turbo", "messages": [{"role": "user", "content": "Hello!"}]}'
 */
export const testAIConnection = async (modelType: 'vision' | 'image' = 'vision'): Promise<{ success: boolean; message: string }> => {
  console.log(`ğŸš€ testAIConnection å‡½æ•°å¼€å§‹æ‰§è¡Œ (${modelType === 'vision' ? 'è§†è§‰æ¨¡å‹' : 'æ–‡ç”Ÿå›¾æ¨¡å‹'})`)
  
  try {
    console.log(`ğŸ” æ£€æŸ¥ ${modelType === 'vision' ? 'è§†è§‰æ¨¡å‹' : 'æ–‡ç”Ÿå›¾æ¨¡å‹'} é…ç½®æœ‰æ•ˆæ€§...`)
    if (!isAIConfigValid(undefined, modelType)) {
      console.log('âŒ AI é…ç½®æ— æ•ˆ')
      return {
        success: false,
        message: `${modelType === 'vision' ? 'è§†è§‰æ¨¡å‹' : 'æ–‡ç”Ÿå›¾æ¨¡å‹'}é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ URLã€API Key å’Œæ¨¡å‹åç§°`
      }
    }
    console.log('âœ… AI é…ç½®æœ‰æ•ˆ')

    console.log('ğŸ”§ è·å–é…ç½®ä¿¡æ¯...')
    const config = getAIConfig()
    const url = modelType === 'vision' ? config.visionUrl : config.imageUrl
    const modelName = modelType === 'vision' ? config.visionModelName : config.imageModelName
    const hasKey = modelType === 'vision' ? !!config.visionKey : !!config.imageKey
    
    console.log('ğŸ“‹ å½“å‰é…ç½®:', {
      url,
      modelName,
      hasKey
    })
    
    const { url: requestUrl, headers } = getAIRequestConfig(modelType)
    console.log('ğŸŒ è¯·æ±‚é…ç½®:', { requestUrl, headers })

    // æ„é€ æ ‡å‡† OpenAI æ ¼å¼çš„æµ‹è¯•è¯·æ±‚
    const requestBody = {
      model: modelName,
      messages: [
        {
          role: "user",
          content: "Hello!"
        }
      ]
    }

    console.log('ğŸ“¤ å‡†å¤‡å‘é€è¯·æ±‚...')
    console.log('è¯·æ±‚ URL:', url)
    console.log('è¯·æ±‚å¤´:', headers)
    console.log('è¯·æ±‚ä½“:', JSON.stringify(requestBody, null, 2))

    const response = await fetch(url, {
      method: 'POST',
      headers,
      body: JSON.stringify(requestBody)
    })

    console.log('ğŸ“¥ æ”¶åˆ°å“åº”:', response.status, response.statusText)

    if (response.ok) {
      const data = await response.json()
      console.log('å“åº”æ•°æ®:', data)
      
      // æ£€æŸ¥æ ‡å‡† OpenAI API å“åº”æ ¼å¼
      // æœŸæœ›æ ¼å¼: { "choices": [{ "message": { "content": "å›å¤å†…å®¹" } }] }
      const reply = data.choices?.[0]?.message?.content
      if (reply && reply.trim().length > 0) {
        return {
          success: true,
          message: `AI æœåŠ¡è¿æ¥æ­£å¸¸ï¼å›å¤: "${reply.trim()}"`
        }
      } else {
        return {
          success: false,
          message: 'è¿æ¥æˆåŠŸä½†å“åº”æ ¼å¼ä¸ç¬¦åˆ OpenAI æ ‡å‡†æˆ–æ— å›å¤å†…å®¹'
        }
      }
    } else {
      const errorText = await response.text().catch(() => 'æ— æ³•è¯»å–é”™è¯¯ä¿¡æ¯')
      console.error('API é”™è¯¯å“åº”:', errorText)
      return {
        success: false,
        message: `è¿æ¥å¤±è´¥: ${response.status} ${response.statusText}`
      }
    }

  } catch (error) {
    console.error('è¿æ¥æµ‹è¯•å¼‚å¸¸:', error)
    return {
      success: false,
      message: `è¿æ¥å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
    }
  }
}