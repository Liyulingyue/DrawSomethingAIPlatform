#!/usr/bin/env python3
"""
Test script for structured output capabilities of Qwen3-VL model via OpenAI API.
Based on backend/app/services/ai.py implementation.
"""

import argparse
import json
import re
import time
import openai
from pathlib import Path
from typing import Any, Dict, List, Optional

# Format instructions from backend
FORMAT_INSTRUCTIONS = (
    "è¯·ä»…è¾“å‡ºä¸€ä¸ª JSON ä»£ç å—ï¼Œä¸¥æ ¼æŒ‰ç…§å¦‚ä¸‹æ ¼å¼è¿”å›ï¼š\n"
    "```json\n"
    "{\n"
    '  "best_guess": "æœ€å¯èƒ½çš„è¯è¯­æˆ–çŸ­è¯­",\n'
    '  "alternatives": ["å¤‡é€‰ç­”æ¡ˆ1", "å¤‡é€‰ç­”æ¡ˆ2"],\n'
    '  "reason": "ç®€è¦çš„è§£é‡Š"\n'
    "}\n"
    "```\n"
    "å…¶ä¸­ alternatives æŒ‰å¯èƒ½æ€§ä»é«˜åˆ°ä½æ’åˆ—ï¼Œå¦‚æ— å¯å¡«ç©ºæ•°ç»„ï¼›ä¸å…è®¸è¾“å‡ºé™¤ä¸Šè¿° JSON ä»£ç å—ä¹‹å¤–çš„ä»»ä½•æ–‡å­—ã€‚"
)

DEFAULT_PROMPT = (
    "ä½ æ˜¯ä¸€ä½èƒ½å¤Ÿç†è§£ç»˜ç”»çš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„å›¾åƒæ¨æµ‹å…¶æ‰€è¡¨è¾¾çš„è¯è¯­æˆ–çŸ­è¯­ï¼Œå¹¶ç”Ÿæˆç­”æ¡ˆã€‚\n"
)

JSON_BLOCK_PATTERN = re.compile(r"```json\s*(.*?)\s*```", re.IGNORECASE | re.DOTALL)

def build_instruction(clue: Optional[str] = None, custom_prompt: Optional[str] = None, language: str = "zh") -> str:
    """Build instruction prompt similar to backend."""
    language = language or 'zh'
    LANGUAGE_PROMPT = f"å½“å‰ç•Œé¢è¯­è¨€æ˜¯{language}ã€‚è¿”å›çš„jsonä¸­ï¼Œkeyéœ€è¦ä¿æŒä¸å˜ï¼Œä½†valueéœ€è¦ä½¿ç”¨{language}å›ç­”ã€‚\n"

    sections: List[str] = []
    sections.append(DEFAULT_PROMPT)
    sections.append(LANGUAGE_PROMPT)

    if custom_prompt and custom_prompt.strip():
        sections.append(custom_prompt.strip())
    if clue:
        sections.append(f"çŒœè¯çš„å‚è€ƒçº¿ç´¢ï¼š{clue}")
    sections.append(FORMAT_INSTRUCTIONS)

    return "\n\n".join(section for section in sections if section)

def extract_json_payload(value: Any) -> Optional[Any]:
    """Extract JSON payload from response, based on backend implementation."""
    if value is None:
        return None
    if isinstance(value, dict):
        keys = {key.lower() for key in value.keys()}
        if {"best_guess", "alternatives"} & keys:
            return value
        for key in ("json", "data", "result", "output", "response", "message", "content"):
            if key in value:
                nested = extract_json_payload(value[key])
                if nested is not None:
                    return nested
        return None
    if isinstance(value, list):
        for item in value:
            nested = extract_json_payload(item)
            if nested is not None:
                return nested
        return None
    if isinstance(value, str):
        text = value.strip()
        if not text:
            return None
        if "</think>" in text:
            text = text.rsplit("</think>", 1)[-1]
        candidates: List[str] = []
        for match in JSON_BLOCK_PATTERN.finditer(text):
            candidates.append(match.group(1).strip())
        candidates.append(text)
        for candidate in candidates:
            if not candidate:
                continue
            try:
                return json.loads(candidate)
            except json.JSONDecodeError:
                continue
        return None
    return None

def coerce_json_guess(payload: Dict[str, Any]) -> Dict[str, Any]:
    """Coerce JSON guess to standard format, based on backend."""
    best_guess = payload.get("best_guess") or payload.get("guess") or payload.get("answer")
    if isinstance(best_guess, list):
        best_list = _ensure_str_list(best_guess)
        best_guess = best_list[0] if best_list else None
        alternatives = best_list[1:]
    else:
        alternatives = []

    if best_guess is not None and not isinstance(best_guess, str):
        best_guess = str(best_guess)

    additional_alternatives = _ensure_str_list(
        payload.get("alternatives")
        or payload.get("candidates")
        or payload.get("others")
        or payload.get("guesses")
    )

    if alternatives:
        existing_lower = {item.lower() for item in alternatives}
        combined = alternatives + [alt for alt in additional_alternatives if alt.lower() not in existing_lower]
    else:
        combined = additional_alternatives

    if not best_guess and combined:
        best_guess = combined[0]
        combined = combined[1:]

    reason = payload.get("reason") or payload.get("explanation") or payload.get("analysis")

    seen_lower = set()
    if isinstance(best_guess, str):
        seen_lower.add(best_guess.lower())

    unique_alternatives: List[str] = []
    for alt in combined:
        lower = alt.lower()
        if lower in seen_lower:
            continue
        seen_lower.add(lower)
        unique_alternatives.append(alt)

    if reason is not None and not isinstance(reason, str):
        reason = str(reason)

    return {
        "best_guess": best_guess,
        "alternatives": unique_alternatives,
        "reason": reason,
    }

def _ensure_str_list(values: Any) -> List[str]:
    """Ensure values is a list of strings."""
    if values is None:
        return []
    if isinstance(values, str):
        return _normalize_candidate_text(values)
    if isinstance(values, list):
        result: List[str] = []
        seen: set[str] = set()
        for item in values:
            if item is None:
                continue
            text = item if isinstance(item, str) else str(item)
            text = text.strip()
            if not text:
                continue
            key = text.lower()
            if key not in seen:
                seen.add(key)
                result.append(text)
        return result
    text = str(values).strip()
    return [text] if text else []

def _normalize_candidate_text(text: str) -> List[str]:
    """Normalize candidate text."""
    cleaned = text.replace("\r", "\n").replace("ï¼Œ", ",").replace("ã€‚", "\n")
    segments: List[str] = []
    for part in cleaned.split("\n"):
        sub_parts = part.split(",") if "," in part else [part]
        for sub in sub_parts:
            candidate = sub.strip(" \t:-ã€‚.,;ï¼›")
            if candidate:
                segments.append(candidate)
    # å»é‡ä½†ä¿æŒé¡ºåº
    seen = set()
    unique: List[str] = []
    for seg in segments:
        key = seg.lower()
        if key not in seen:
            seen.add(key)
            unique.append(seg)
    return unique

def extract_guesses(data: Dict[str, Any]) -> Dict[str, Any]:
    """Extract guesses from response data."""
    structured = extract_json_payload(data)
    if isinstance(structured, list):
        for item in structured:
            if isinstance(item, dict):
                structured = item
                break
        else:
            structured = None

    if isinstance(structured, dict):
        coerced = coerce_json_guess(structured)
        if coerced.get("best_guess") or coerced.get("alternatives"):
            return coerced

    # Fallback: try to extract from raw text
    if isinstance(data, dict) and "result" in data:
        raw_text = data["result"]
        structured = extract_json_payload(raw_text)
        if structured:
            coerced = coerce_json_guess(structured)
            if coerced.get("best_guess") or coerced.get("alternatives"):
                return coerced

    return {
        "best_guess": None,
        "alternatives": [],
        "reason": "æ— æ³•è§£æç»“æ„åŒ–è¾“å‡º"
    }

def test_structured_output_via_api(base_url="http://localhost:8000/v1", api_key="dummy", model="qwen3-vl-openvino", clue=None, custom_prompt=None, language="zh", max_tokens=200):
    """Test structured output capabilities via OpenAI API."""
    client = openai.OpenAI(
        api_key=api_key,
        base_url=base_url
    )

    print(f"ğŸ” æµ‹è¯•ç»“æ„åŒ–è¾“å‡º via API: {base_url}")
    print(f"ğŸ¤– æ¨¡å‹: {model}")
    if clue:
        print(f"ğŸ’¡ çº¿ç´¢: {clue}")
    print(f"ğŸŒ è¯­è¨€: {language}")
    print("-" * 60)

    # Build instruction
    instruction = build_instruction(clue, custom_prompt, language)
    print(f"ğŸ“ æ„å»ºæŒ‡ä»¤å®Œæˆ (é•¿åº¦: {len(instruction)} å­—ç¬¦)")

    # Run inference via API
    print("ğŸ¤– æ­£åœ¨é€šè¿‡ API è¿è¡Œæ¨ç†...")
    start_time = time.time()
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": instruction}
            ],
            max_tokens=max_tokens
        )

        response_text = response.choices[0].message.content
        inference_time = time.time() - start_time
        print(f"âœ… API æ¨ç†å®Œæˆ (è€—æ—¶: {inference_time:.2f} ç§’)")

    except Exception as e:
        inference_time = time.time() - start_time
        print(f"âŒ API è°ƒç”¨å¤±è´¥ (è€—æ—¶: {inference_time:.2f} ç§’): {e}")
        return None

    print("-" * 60)

    # Parse response
    print("ğŸ” è§£æå“åº”...")
    parse_start_time = time.time()
    mock_data = {"result": response_text}
    parsed_result = extract_guesses(mock_data)
    parse_time = time.time() - parse_start_time
    print(f"âœ… è§£æå®Œæˆ (è€—æ—¶: {parse_time:.3f} ç§’)")

    print("ğŸ“Š è§£æç»“æœ:")
    print(f"  æœ€ä½³çŒœæµ‹: {parsed_result.get('best_guess', 'æ— ')}")
    print(f"  å¤‡é€‰ç­”æ¡ˆ: {parsed_result.get('alternatives', [])}")
    print(f"  åŸå› : {parsed_result.get('reason', 'æ— ')}")
    print("-" * 60)

    print("ğŸ“„ åŸå§‹å“åº”:")
    print(response_text)
    print("-" * 60)

    # Validate structure
    has_best_guess = parsed_result.get('best_guess') is not None
    has_alternatives = len(parsed_result.get('alternatives', [])) > 0
    has_reason = parsed_result.get('reason') is not None

    print("âœ… ç»“æ„éªŒè¯:")
    print(f"  åŒ…å«æœ€ä½³çŒœæµ‹: {'æ˜¯' if has_best_guess else 'å¦'}")
    print(f"  åŒ…å«å¤‡é€‰ç­”æ¡ˆ: {'æ˜¯' if has_alternatives else 'å¦'}")
    print(f"  åŒ…å«åŸå› : {'æ˜¯' if has_reason else 'å¦'}")

    success = has_best_guess and has_alternatives and has_reason
    print(f"ğŸ¯ ç»“æ„åŒ–è¾“å‡ºæµ‹è¯•: {'é€šè¿‡' if success else 'å¤±è´¥'}")

    # Print timing summary
    total_time = inference_time + parse_time
    print("-" * 60)
    print("â±ï¸  æ—¶é—´ç»Ÿè®¡:")
    print(f"  API æ¨ç†æ—¶é—´: {inference_time:.2f} ç§’")
    print(f"  å“åº”è§£ææ—¶é—´: {parse_time:.3f} ç§’")
    print(f"  æ€»è€—æ—¶: {total_time:.2f} ç§’")

    return parsed_result

def main():
    parser = argparse.ArgumentParser(description="Test structured output capabilities of Qwen3-VL model via OpenAI API")
    parser.add_argument("--base_url", default="http://localhost:8000/v1", help="API base URL")
    parser.add_argument("--api_key", default="dummy", help="API key (not used)")
    parser.add_argument("--model", default="qwen3-vl-openvino", help="Model name")
    parser.add_argument("--clue", help="Clue for guessing")
    parser.add_argument("--custom_prompt", help="Custom prompt")
    parser.add_argument("--language", default="zh", help="Language (zh/en)")
    parser.add_argument("--max_tokens", type=int, default=200, help="Max tokens for response")

    args = parser.parse_args()

    test_structured_output_via_api(
        args.base_url,
        args.api_key,
        args.model,
        args.clue,
        args.custom_prompt,
        args.language,
        args.max_tokens
    )

if __name__ == "__main__":
    main()