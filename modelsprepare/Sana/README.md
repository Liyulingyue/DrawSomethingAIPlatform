# Sana OpenVINO 模型准备

此文件夹包含准备 Sana 模型以供 OpenVINO 使用的说明和资源。

## 概述

**Sana** 是一个文本到图像框架，能够高效生成高达 4096 × 4096 分辨率的图像，由 NVLabs 开发。Sana 能够在以极快速度合成高分辨率、高质量图像，并具有强大的文本-图像对齐。

核心设计包括：
- **深度压缩自编码器**：与传统 AE 仅压缩 8× 不同，我们训练了一个能够压缩图像 32× 的 AE，有效减少潜在令牌的数量。
- **线性 DiT**：作者将 DiT 中的所有香草注意力替换为线性注意力，在高分辨率下更高效而不牺牲质量。
- **仅解码器文本编码器**：T5 被现代仅解码器小型 LLM 替换作为文本编码器，并设计了复杂的人类指令与上下文学习以增强图像-文本对齐。
- **高效训练和采样**：提出 Flow-DPM-Solver 以减少采样步骤，通过高效的标题标注和选择来加速收敛。

**SANA-1.5** 是一个线性扩散变换器，用于文本到图像生成的有效扩展。SANA-1.5 基于 SANA-1.0 构建，并引入以下改进：
- **高效训练扩展**：深度增长范式，使参数从 1.6B 扩展到 4.8B，同时显著减少计算资源，并结合内存高效的 8 位优化器。
- **模型深度修剪**：块重要性分析技术，用于高效模型压缩到任意大小，最小化质量损失。
- **推理时间扩展**：重复采样策略，以计算换取模型容量，使较小模型在推理时匹配较大模型质量。

**SANA-Sprint** 是一个高效扩散模型，用于超快文本到图像。SANA-Sprint 基于预训练基础模型，并通过混合蒸馏增强，将推理步骤从 20 减少到 1-4。

核心创新包括：
- **无训练转换到 TrigFlow**：论文提出了一种无训练方法，将预训练流匹配模型转换为连续时间一致性蒸馏 (sCM)，消除从头开始的昂贵训练，实现高训练效率。混合蒸馏策略结合 sCM 和潜在对抗蒸馏 (LADD)：sCM 确保与教师模型对齐，而 LADD 增强单步生成保真度。
- **稳定连续时间蒸馏**：为了稳定连续时间一致性蒸馏，我们解决了两个关键挑战：当扩展模型大小和增加分辨率时发生的训练不稳定性和过大梯度范数，导致模型崩溃。我们通过细化密集时间嵌入并将 QK-归一化集成到自注意力和交叉注意力机制中来实现这一点。这些修改实现了高效训练并提高了稳定性，允许在更高分辨率和更大模型大小下稳健性能。
- **使用 GAN 改进连续时间 CM**：CTM 分析 CM 以局部方式蒸馏教师信息，其中在每次迭代中，学生模型从局部时间间隔学习。这导致模型在隐式外推下学习跨时间步信息，这可能减慢收敛速度。为了解决这一限制，我们引入额外的对抗损失以提供跨不同时间步的直接全局监督，提高收敛速度和输出质量。

## 准备步骤

要为 OpenVINO 准备 Sana 模型，请按照父目录 `modelsprepare/` 中的 notebook `sana-image-generation.ipynb` 中的步骤操作。

该 notebook 涵盖：
- 先决条件
- 选择模型变体
- 使用 Optimum Intel 使用 OpenVINO 转换和优化模型
- 压缩模型权重
- 运行 OpenVINO 模型推理
- 交互式演示

有关详细说明，请参考 [sana-image-generation.ipynb](../sana-image-generation.ipynb)。

有关模型的更多详细信息，请参见 [Sana 论文](https://arxiv.org/abs/2410.10629)、[模型页面](https://nvlabs.github.io/Sana/) 和原始 [仓库](https://github.com/NVlabs/Sana)。