#!/usr/bin/env python
"""
SmolVLM-256M-Instruct åŸç”Ÿæ¨ç†æœåŠ¡
åŸºäº transformers å’Œ modelscopeï¼Œæä¾› OpenAI å…¼å®¹çš„ API
"""

import os
import sys
import base64
import asyncio
from pathlib import Path
from typing import Optional, List
from datetime import datetime
import uuid

import torch
from PIL import Image
from io import BytesIO

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

try:
    from modelscope import AutoProcessor, AutoModelForVision2Seq
except ImportError:
    print("âŒ æœªå®‰è£… modelscopeï¼Œè¯·å…ˆè¿è¡Œ:")
    print("pip install modelscope transformers pillow torch")
    sys.exit(1)

# ==================== é…ç½® ====================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_NAME = "HuggingFaceTB/SmolVLM-256M-Instruct"
HOST = "127.0.0.1"
PORT = 8888

print(f"ğŸ”§ è®¾å¤‡: {DEVICE}")
print(f"ğŸ¤– æ¨¡å‹: {MODEL_NAME}")

# ==================== æ¨¡å‹åŠ è½½ ====================
print("ğŸ”„ åŠ è½½æ¨¡å‹ä¸­...")

processor = AutoProcessor.from_pretrained(MODEL_NAME)
model = AutoModelForVision2Seq.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.bfloat16,
    _attn_implementation="flash_attention_2" if DEVICE == "cuda" else "eager",
).to(DEVICE)

print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# ==================== FastAPI åº”ç”¨ ====================
app = FastAPI(title="SmolVLM Service", version="1.0.0")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== æ•°æ®æ¨¡å‹ ====================
class ChatMessage(BaseModel):
    role: str  # "user" or "assistant"
    content: str | List[dict]  # æ–‡æœ¬æˆ– [{"type": "image", ...}, {"type": "text", "text": "..."}]

class ChatCompletionRequest(BaseModel):
    model: str = "smolvlm-256m"
    messages: List[ChatMessage]
    temperature: float = 0.7
    max_tokens: int = 512
    top_p: float = 0.9

class ChatChoice(BaseModel):
    index: int
    message: ChatMessage
    finish_reason: str

class ChatCompletionResponse(BaseModel):
    id: str
    object: str = "chat.completion"
    created: int
    model: str
    choices: List[ChatChoice]
    usage: dict

# ==================== å·¥å…·å‡½æ•° ====================
def decode_image_from_base64(image_data: str) -> Image.Image:
    """ä» base64 è§£ç å›¾åƒ"""
    image_bytes = base64.b64decode(image_data)
    image = Image.open(BytesIO(image_bytes))
    return image

def encode_image_to_base64(image: Image.Image) -> str:
    """å°†å›¾åƒç¼–ç ä¸º base64"""
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

@torch.no_grad()
def generate_response(messages: List[ChatMessage], max_tokens: int = 512) -> str:
    """ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå“åº”"""
    # æå–æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯å’Œç›¸å…³å›¾åƒ
    images = []
    text_content = ""
    
    print(f"\n[generate_response] å¼€å§‹å¤„ç† {len(messages)} æ¡æ¶ˆæ¯")
    
    # å¤„ç†æ¶ˆæ¯ï¼Œæå–å›¾åƒå’Œæ–‡æœ¬
    for msg_idx, msg in enumerate(messages):
        print(f"  æ¶ˆæ¯ {msg_idx}: role={msg.role}, content_type={type(msg.content).__name__}")
        
        if msg.role == "user":
            if isinstance(msg.content, str):
                # çº¯æ–‡æœ¬æ¶ˆæ¯
                print(f"    âœ… çº¯æ–‡æœ¬æ¶ˆæ¯: {msg.content[:50]}")
                text_content = msg.content
            elif isinstance(msg.content, list):
                # å¤šæ¨¡æ€æ¶ˆæ¯ (OpenAI æ ¼å¼)
                print(f"    ğŸ“¦ åˆ—è¡¨æ¶ˆæ¯ï¼ŒåŒ…å« {len(msg.content)} é¡¹")
                for item_idx, item in enumerate(msg.content):
                    print(f"      é¡¹ {item_idx}: {item}")
                    
                    if isinstance(item, dict):
                        if item.get("type") == "text":
                            text_content = item.get("text", "")
                            print(f"        ğŸ“ æå–æ–‡æœ¬: {text_content[:50]}")
                        elif item.get("type") == "image_url":
                            # å¤„ç† OpenAI image_url æ ¼å¼
                            image_url = item.get("image_url", {})
                            url = image_url.get("url", "") if isinstance(image_url, dict) else image_url
                            
                            print(f"        ğŸ”— image_url: {url[:80]}...")
                            
                            if url.startswith("data:image"):
                                # Base64 ç¼–ç çš„å›¾åƒ
                                try:
                                    base64_str = url.split(",", 1)[1]
                                    image = decode_image_from_base64(base64_str)
                                    images.append(image)
                                    print(f"        âœ… ä» data URI åŠ è½½å›¾åƒæˆåŠŸï¼Œå¤§å°: {image.size}")
                                except Exception as e:
                                    print(f"        âŒ ä» data URI åŠ è½½å›¾åƒå¤±è´¥: {e}")
                            else:
                                print(f"        âš ï¸ è·³è¿‡é base64 URL")
                        elif item.get("type") == "image":
                            # å¤„ç†è‡ªå®šä¹‰ image æ ¼å¼ï¼ˆä»…ç±»å‹æ ‡è®°ï¼‰
                            if "data" in item:
                                try:
                                    image = decode_image_from_base64(item["data"])
                                    images.append(image)
                                    print(f"        âœ… ä» data å­—æ®µåŠ è½½å›¾åƒæˆåŠŸ")
                                except Exception as e:
                                    print(f"        âŒ ä» data å­—æ®µåŠ è½½å›¾åƒå¤±è´¥: {e}")
    
    print(f"\n[ç»Ÿè®¡] æå–çš„æ–‡æœ¬é•¿åº¦: {len(text_content)}, æå–çš„å›¾åƒæ•°: {len(images)}")
    
    if len(images) == 0:
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ°å›¾åƒï¼Œåªå¤„ç†æ–‡æœ¬")
    
    # æ„å»º SmolVLM æ ¼å¼çš„æ¶ˆæ¯
    formatted_messages = [
        {
            "role": "user",
            "content": [
                {"type": "image"} for _ in images
            ] + [{"type": "text", "text": text_content}]
        }
    ]
    
    print(f"[æ ¼å¼åŒ–æ¶ˆæ¯] {formatted_messages}")
    
    # åº”ç”¨èŠå¤©æ¨¡æ¿
    prompt = processor.apply_chat_template(formatted_messages, add_generation_prompt=True)
    
    print(f"ğŸ“ åº”ç”¨æ¨¡æ¿åçš„ Prompt é•¿åº¦: {len(prompt)}, é¦– 100 å­—: {prompt[:100]}")
    
    # å¤„ç†è¾“å…¥
    inputs = processor(
        text=prompt,
        images=images if images else None,
        return_tensors="pt"
    )
    inputs = inputs.to(DEVICE)
    
    print(f"âœ… è¾“å…¥å·²å‡†å¤‡: {list(inputs.keys())}")
    for key, val in inputs.items():
        if hasattr(val, 'shape'):
            print(f"    {key}: shape={val.shape}")
    
    # ç”Ÿæˆè¾“å‡º
    print(f"ğŸ”„ ç”Ÿæˆä¸­... (max_tokens={max_tokens})")
    generated_ids = model.generate(
        **inputs,
        max_new_tokens=max_tokens,
        do_sample=True,
        temperature=0.7,
    )
    
    # è§£ç 
    generated_texts = processor.batch_decode(
        generated_ids,
        skip_special_tokens=True,
    )
    
    response = generated_texts[0]
    print(f"âœ… ç”Ÿæˆå®Œæˆ: {response[:100]}...")
    
    return response

# ==================== API ç«¯ç‚¹ ====================

@app.get("/v1/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    return {
        "object": "list",
        "data": [
            {
                "id": "smolvlm-256m",
                "object": "model",
                "created": int(datetime.now().timestamp()),
                "owned_by": "transformers",
                "permission": [],
                "root": "smolvlm-256m",
                "parent": None
            }
        ]
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "model": "SmolVLM-256M-Instruct",
        "device": DEVICE,
        "message": "SmolVLM service is running"
    }

@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest):
    """
    èŠå¤©è¡¥å…¨ (OpenAI å…¼å®¹)
    
    æ”¯æŒçš„æ¶ˆæ¯æ ¼å¼:
    - çº¯æ–‡æœ¬: {"role": "user", "content": "é—®é¢˜"}
    - å¤šæ¨¡æ€ (OpenAI æ ‡å‡†): {"role": "user", "content": [{"type": "text", "text": "é—®é¢˜"}, {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}]}
    - å¤šæ¨¡æ€ (è‡ªå®šä¹‰): {"role": "user", "content": [{"type": "image", "data": "base64_image"}, {"type": "text", "text": "é—®é¢˜"}]}
    """
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ“¨ æ”¶åˆ°è¯·æ±‚ï¼Œæ¶ˆæ¯æ•°: {len(request.messages)}")
        
        # è°ƒè¯•: æ‰“å°æ¶ˆæ¯ç»“æ„
        for i, msg in enumerate(request.messages):
            if isinstance(msg.content, list):
                print(f"  æ¶ˆæ¯ {i}: role={msg.role}, content=[", end="")
                for item in msg.content:
                    if isinstance(item, dict):
                        if item.get("type") == "image_url":
                            url = item.get("image_url", {})
                            if isinstance(url, dict):
                                url_str = url.get("url", "")[:50]
                            else:
                                url_str = str(url)[:50]
                            print(f"{{type: image_url, url_preview: {url_str}...}}", end=" ")
                        else:
                            print(f"{{type: {item.get('type')}}}", end=" ")
                print("]")
            else:
                print(f"  æ¶ˆæ¯ {i}: role={msg.role}, content={str(msg.content)[:50]}")
        
        # ç”Ÿæˆå“åº”
        response_text = generate_response(
            request.messages,
            max_tokens=request.max_tokens
        )
        
        # æ„é€  OpenAI æ ¼å¼çš„å“åº”
        completion_id = f"chatcmpl-{uuid.uuid4().hex[:12]}"
        created_time = int(datetime.now().timestamp())
        
        response = ChatCompletionResponse(
            id=completion_id,
            created=created_time,
            model="smolvlm-256m",
            choices=[
                ChatChoice(
                    index=0,
                    message=ChatMessage(
                        role="assistant",
                        content=response_text
                    ),
                    finish_reason="stop"
                )
            ],
            usage={
                "prompt_tokens": len(request.messages[0].content) if request.messages else 0,
                "completion_tokens": len(response_text.split()),
                "total_tokens": len(request.messages[0].content) + len(response_text.split()) if request.messages else 0,
            }
        )
        
        return response.model_dump()
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/vision/describe")
async def describe_image(file: UploadFile = File(...), prompt: str = "æè¿°è¿™å¼ å›¾ç‰‡"):
    """
    æè¿°å›¾åƒ (ç›´æ¥ä¸Šä¼ æ–‡ä»¶)
    """
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ“¸ æ”¶åˆ°å›¾åƒ: {file.filename}")
        
        # è¯»å–å›¾åƒ
        image_data = await file.read()
        image = Image.open(BytesIO(image_data))
        
        # å‡†å¤‡æ¶ˆæ¯
        messages = [
            ChatMessage(
                role="user",
                content=[
                    {"type": "image"},
                    {"type": "text", "text": prompt}
                ]
            )
        ]
        
        # ç”Ÿæˆå“åº”
        response_text = generate_response([messages[0]])
        
        return {
            "status": "success",
            "prompt": prompt,
            "result": response_text
        }
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "name": "SmolVLM Service",
        "version": "1.0.0",
        "model": "SmolVLM-256M-Instruct",
        "device": DEVICE,
        "endpoints": {
            "/v1/models": "åˆ—å‡ºæ¨¡å‹",
            "/v1/chat/completions": "èŠå¤©è¡¥å…¨ (OpenAI å…¼å®¹)",
            "/v1/vision/describe": "å›¾åƒæè¿°",
            "/health": "å¥åº·æ£€æŸ¥",
            "/docs": "API æ–‡æ¡£"
        }
    }

# ==================== å¯åŠ¨å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ SmolVLM-256M-Instruct æœåŠ¡å¯åŠ¨")
    print("=" * 60)
    print()
    print(f"ğŸ“ ç›‘å¬åœ°å€: http://{HOST}:{PORT}")
    print(f"ğŸ“š API æ–‡æ¡£: http://{HOST}:{PORT}/docs")
    print(f"ğŸ¥ å¥åº·æ£€æŸ¥: http://{HOST}:{PORT}/health")
    print()
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print()
    
    uvicorn.run(
        app,
        host=HOST,
        port=PORT,
        log_level="info",
    )

if __name__ == "__main__":
    main()
